{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75f602a-272b-4c70-87c9-339dc0229fa2",
   "metadata": {},
   "source": [
    "THIS NOTEBOOK CONTAINS THE CODE TO EXTRACT SMALLER DATASET from FOOD101 AND VALIDATION DATASET.\n",
    "\n",
    "THEN CONVERT THE DATASETs INTO METADATA CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f34b712-b10e-4ab8-8214-0cfd840d083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "food101_metadata = pd.read_csv('food101_metadata_full.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c427fc35-71b0-417b-b160-34639a288094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98000\n"
     ]
    }
   ],
   "source": [
    "full_dataset = pd.concat([food101_metadata], ignore_index = True)\n",
    "print(len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb99504-c910-4e50-b881-23e7c1f46e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique ingredients in dataset\n",
    "def checkIng(dataset):\n",
    "    val_ing = set()\n",
    "    if len(dataset) == 0: return val_ing\n",
    "    for i in dataset['Ingredients']:\n",
    "        l = i.split(\",\")\n",
    "        for j in l:\n",
    "            val_ing.add(j)\n",
    "    return val_ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "241bc08c-bb8a-4b8d-9daf-2d9acc99f868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset ingredients 878\n",
      "full dataset categories 98\n"
     ]
    }
   ],
   "source": [
    "# Food101 original dataset has 878 ingredients and 98 categories\n",
    "ing_full = checkIng(full_dataset)\n",
    "print(\"full dataset ingredients\", len(checkIng(full_dataset)))\n",
    "\n",
    "print(\"full dataset categories\", len(full_dataset['Category'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb077c7-d0f1-44e1-97b9-2dc2f7ad2ae7",
   "metadata": {},
   "source": [
    "CREATING smaller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3e55780-9703-427a-a685-a76b4f402a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort ingredients based on number of records it is present in \n",
    "from collections import OrderedDict\n",
    "\n",
    "def getSortedIngCounts(dataset):    \n",
    "    ingredient_counts = {}\n",
    "    if len(dataset) == 0: return ingredient_counts\n",
    "    for ingredients in dataset['Ingredients']:\n",
    "        for ingredient in ingredients.split(\",\"):\n",
    "            if ingredient in ingredient_counts:\n",
    "                ingredient_counts[ingredient] += 1\n",
    "            else:\n",
    "                ingredient_counts[ingredient] = 1\n",
    "    sorted_ingredient_counts = OrderedDict(sorted(ingredient_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_ingredient_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34a14839-5339-4493-9801-1c5bc40d406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForbiddenIng(sorted_ingredient_counts, dataset):    \n",
    "    forbidden_ingredients = set()\n",
    "    sorted_dict_list = list(sorted_ingredient_counts.items())\n",
    "\n",
    "    for ingredient, count in sorted_dict_list[::-1]:\n",
    "        if len(forbidden_ingredients) < 28:\n",
    "            forbidden_ingredients.add(ingredient)\n",
    "        else:\n",
    "            break\n",
    "    return forbidden_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f5c5ba7-9978-4bb7-9457-487a94d25ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller subset of the original dataset with ALL categories and Ingredients\n",
    "import pandas as pd\n",
    "\n",
    "smaller_df = pd.DataFrame()\n",
    "for category, group in full_dataset.groupby('Category'):\n",
    "    if len(group) >= 500:\n",
    "        sampled_rows = group.sample(n=500, random_state=42)  \n",
    "    else:\n",
    "        sampled_rows = group\n",
    "    smaller_df = pd.concat([smaller_df, sampled_rows])\n",
    "\n",
    "smaller_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5489683-24ba-409d-bec7-47d640dcbccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller df ingr:  878\n",
      "Smaller df categories:  98\n"
     ]
    }
   ],
   "source": [
    "# checking the unique categories and ingredients in the smaller dataset\n",
    "ing_small = checkIng(smaller_df)\n",
    "cat_small = smaller_df['Category'].unique()\n",
    "\n",
    "print(\"Smaller df ingr: \", len(ing_small))\n",
    "print(\"Smaller df categories: \", len(cat_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae42db45-011a-47c9-95d4-a1c5241b9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ingr_counts = getSortedIngCounts(smaller_df2)\n",
    "small_forbidden_ing = getForbiddenIng(small_ingr_counts, smaller_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f042d7-b677-40f8-a27c-8dbe9088fd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df2.equals(smaller_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98e61717-a307-4bd0-a1c5-e9108f06a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropForbiddenIngr(dataset, forbidden_ing):\n",
    "    for index, row in dataset.iterrows():\n",
    "        \n",
    "        ingredients = row['Ingredients'].split(\",\")\n",
    "        if any(ingredient in forbidden_ing for ingredient in ingredients):\n",
    "            dataset.drop(dataset.index[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af0467c6-5070-413d-be9e-e9bc2a5faf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48847"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smaller_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "296fb58f-2352-4658-9d4f-ce19e9ca747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropForbiddenIngrIndex(dataset, forbidden_ing):\n",
    "    for index, row in dataset.iterrows():\n",
    "        ingredients = row['Ingredients'].split(\",\")\n",
    "        if any(ingredient in forbidden_ing for ingredient in ingredients):\n",
    "            dataset.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8a3b47e-e857-4b52-8857-274fdee7897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropForbiddenIngr(smaller_df, small_forbidden_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "feb80c6a-4582-42f8-bb5a-75983716d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropForbiddenIngrIndex(smaller_df2, small_forbidden_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "afc2ab17-d8c7-4db1-a30d-d71c92db75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(smaller_df) == set(smaller_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3e77a45-b234-4f93-ad6a-63c1a5fbcd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated smaller_df ing:  850\n",
      "Updated smaller_df cat:  98\n"
     ]
    }
   ],
   "source": [
    "ing_small = checkIng(smaller_df)\n",
    "\n",
    "print(\"Updated smaller_df ing: \", len(ing_small))\n",
    "print(\"Updated smaller_df cat: \", len(smaller_df['Category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbfbc3c4-6969-4e44-83d3-b32d4c01a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# checking if we missed any ingredients from the original Food101\n",
    "ing_remain = ing_full - ing_small\n",
    "print(ing_remain == small_forbidden_ing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da6709-516d-490e-ae78-7c2862145cc1",
   "metadata": {},
   "source": [
    "CREATING VALIDATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af4c84f9-51f9-4e6b-9ccf-1074f4c119ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here extracting the remaining records from Food101 which are NOT present in the \n",
    "# smaller dataset which is used for training. \n",
    "merged_df = pd.merge(dataset_metadata, smaller_df, on=list(dataset_metadata.columns), how='left', indicator=True)\n",
    "\n",
    "# Filter the merged DataFrame to keep only the rows that are not in smaller_df\n",
    "df1_filtered = merged_df.query('_merge != \"both\"')\n",
    "\n",
    "df1_filtered.reset_index(drop=True, inplace=True)\n",
    "df1_filtered = df1_filtered.drop(\"_merge\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83483db1-e580-4837-80f3-cbdd54c37e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_filtered = df1_filtered[df1_filtered.apply(lambda row: row['Category'] in cat and all(ingredient not in ing_remain for ingredient in row['Ingredients'].split(\",\")), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fa1b538-2463-4864-a4b5-cb2257277af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining ing:  878\n",
      "remaining cats:  98\n"
     ]
    }
   ],
   "source": [
    "# checking if the unique categories & ingredients in the filtered dataset are matching with \n",
    "# smaller dataset \n",
    "ing_fil = checkIng(df1_filtered)\n",
    "\n",
    "print(\"remaining ing: \", len(ing_fil))\n",
    "print(\"remaining cats: \", len(df1_filtered['Category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02ae524a-8370-47e2-95fe-98eb2c753e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49153"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57d16306-42d5-4b8e-9134-dfa87b1a382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping forbidden ing rows from filtered df\n",
    "dropForbiddenIngr(df1_filtered, small_forbidden_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7f198c6-b588-4763-b06e-eaf04b70b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered ing 850\n",
      "Filtered cat 98\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered ing\", len(checkIng(df1_filtered)))\n",
    "print(\"Filtered cat\", len(df1_filtered['Category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "bf5454e8-8f29-46fa-9a48-96ae6d6c2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING Validation dataset - THIS dataset SHOULD have\n",
    "# the SAME number of Categories and Ingredients AS the smaller_df \n",
    "# which is used for training \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# validation_dataset = df1_filtered\n",
    "# # dataset_metadata[~dataset_metadata.isin(smaller_df)].dropna()\n",
    "\n",
    "# categories_in_smaller_df = set(smaller_df['Category'].unique())\n",
    "# ingredients_in_smaller_df = ing_small\n",
    "\n",
    "# final_validation_dataset = pd.DataFrame()\n",
    "\n",
    "# while (\n",
    "#     final_validation_dataset.empty\n",
    "#     or set(final_validation_dataset['Category'].unique()) != categories_in_smaller_df\n",
    "#     or ingredients_in_smaller_df != checkIng(final_validation_dataset)\n",
    "# ):\n",
    "#     final_validation_dataset = pd.DataFrame()\n",
    "\n",
    "#     for category in categories_in_smaller_df:\n",
    "#         category_records = validation_dataset[\n",
    "#             (validation_dataset['Category'] == category)\n",
    "#         ].sample(n=100, replace=True)  \n",
    "\n",
    "#         final_validation_dataset = pd.concat([final_validation_dataset, category_records])\n",
    "\n",
    "# final_validation_dataset = final_validation_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# new_val_df = pd.DataFrame()\n",
    "# for category, group in df1_filtered.groupby('Category'):\n",
    "\n",
    "#     if len(group) >= 100:\n",
    "#         sampled_rows = group.sample(n=100, random_state=42) \n",
    "#     else:\n",
    "#         sampled_rows = group\n",
    "#     new_val_df = pd.concat([new_val_df, sampled_rows])\n",
    "\n",
    "# new_val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c96fe485-fa6e-4d63-9b8a-24dfbcae8821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "842\n",
      "839\n",
      "845\n",
      "847\n",
      "842\n",
      "846\n",
      "842\n",
      "846\n",
      "844\n",
      "844\n",
      "845\n",
      "841\n",
      "844\n",
      "841\n",
      "842\n",
      "844\n",
      "844\n",
      "846\n",
      "840\n",
      "845\n",
      "845\n",
      "844\n",
      "845\n",
      "842\n",
      "843\n",
      "843\n",
      "846\n",
      "844\n",
      "839\n",
      "843\n",
      "844\n",
      "841\n",
      "842\n",
      "844\n",
      "842\n",
      "846\n",
      "847\n",
      "845\n",
      "843\n",
      "845\n",
      "843\n",
      "847\n",
      "840\n",
      "844\n",
      "846\n",
      "844\n",
      "844\n",
      "846\n",
      "845\n",
      "845\n",
      "846\n",
      "844\n",
      "846\n",
      "845\n",
      "844\n",
      "843\n",
      "848\n",
      "844\n",
      "844\n",
      "841\n",
      "843\n",
      "842\n",
      "844\n",
      "842\n",
      "839\n",
      "845\n",
      "847\n",
      "845\n",
      "844\n",
      "847\n",
      "845\n",
      "846\n",
      "845\n",
      "843\n",
      "841\n",
      "842\n",
      "847\n",
      "842\n",
      "845\n",
      "847\n",
      "844\n",
      "846\n",
      "839\n",
      "846\n",
      "844\n",
      "844\n",
      "841\n",
      "840\n",
      "845\n",
      "844\n",
      "846\n",
      "842\n",
      "845\n",
      "845\n",
      "843\n",
      "838\n",
      "845\n",
      "843\n",
      "845\n",
      "845\n",
      "847\n",
      "843\n",
      "842\n",
      "844\n",
      "840\n",
      "839\n",
      "842\n",
      "848\n",
      "847\n",
      "844\n",
      "844\n",
      "847\n",
      "847\n",
      "842\n",
      "845\n",
      "843\n",
      "846\n",
      "844\n",
      "842\n",
      "843\n",
      "840\n",
      "841\n",
      "848\n",
      "839\n",
      "843\n",
      "843\n",
      "846\n",
      "843\n",
      "845\n",
      "844\n",
      "841\n",
      "845\n",
      "846\n",
      "839\n",
      "844\n",
      "844\n",
      "843\n",
      "842\n",
      "844\n",
      "845\n",
      "846\n",
      "842\n",
      "844\n",
      "841\n",
      "845\n",
      "841\n",
      "846\n",
      "842\n",
      "842\n",
      "844\n",
      "845\n",
      "846\n",
      "843\n",
      "844\n",
      "842\n",
      "844\n",
      "845\n",
      "843\n",
      "843\n",
      "844\n",
      "842\n",
      "842\n",
      "845\n",
      "841\n",
      "844\n",
      "846\n",
      "844\n",
      "843\n",
      "845\n",
      "842\n",
      "844\n",
      "844\n",
      "843\n",
      "842\n",
      "847\n",
      "845\n",
      "843\n",
      "843\n",
      "841\n",
      "842\n",
      "847\n",
      "843\n",
      "842\n",
      "843\n",
      "844\n",
      "844\n",
      "841\n",
      "845\n"
     ]
    }
   ],
   "source": [
    "final_val_df = pd.DataFrame()\n",
    "\n",
    "while len(checkIng(final_val_df)) != 850:\n",
    "    print(len(checkIng(final_val_df)))\n",
    "    final_val_df = pd.DataFrame()\n",
    "    for category, group in df1_filtered.groupby('Category'):\n",
    "        if len(group) >= 150:\n",
    "            sampled_rows = group.sample(n=150)\n",
    "        else:\n",
    "            sampled_rows = group\n",
    "        final_val_df = pd.concat([final_val_df, sampled_rows])\n",
    "\n",
    "final_val_df.reset_index(drop=True, inplace=True)\n",
    "# while len(checkIng(final_val_df)) != 850 && getSortedIngCounts(final_val_df).keys() in small_forbidden_ing:\n",
    "#     print(len(checkIng(final_val_df)))\n",
    "#     final_val_df = pd.DataFrame()\n",
    "#     for category, group in df1_filtered.groupby('Category'):\n",
    "#         if len(group) >= 100:\n",
    "#             sampled_rows = group.sample(n=100)\n",
    "#         else:\n",
    "#             sampled_rows = group\n",
    "#         final_val_df = pd.concat([final_val_df, sampled_rows])\n",
    "\n",
    "# final_val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e6de2f-dfc1-4671-a04d-76266caae1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ings:  850\n",
      "Validation Cats:  98\n"
     ]
    }
   ],
   "source": [
    "# CHECKING if unique ingredients & categories are MATCHING with the unique ingredients\n",
    "# & categories in the TRAINING DATASET!!\n",
    "ing_val = checkIng(final_val_df)\n",
    "print(\"Validation ings: \", len(ing_val))\n",
    "\n",
    "cat_val = final_val_df['Category'].unique()\n",
    "print(\"Validation Cats: \", len(cat_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f484bf6-dd75-4b0c-bd75-117681a4c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ings:  850\n",
      "Validation Cats:  98\n"
     ]
    }
   ],
   "source": [
    "# CHECKING if unique ingredients & categories are MATCHING with the unique ingredients\n",
    "# & categories in the TRAINING DATASET!!\n",
    "ing_small = checkIng(smaller_df)\n",
    "print(\"Validation ings: \", len(ing_small))\n",
    "\n",
    "cat_small = smaller_df['Category'].unique()\n",
    "print(\"Validation Cats: \", len(cat_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2a22dc-b4dd-4c1c-860e-b53d6b7566e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ingredient_counts = getSortedIngCounts(final_val_df)\n",
    "ingredient_counts = getSortedIngCounts(smaller_df)\n",
    "for k, v in val_ingredient_counts.items():\n",
    "    if(k not in ingredient_counts.keys()):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da6e000-dd2c-4ca2-b894-872d379ae927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INGREDIENTS same in small & validation:  True\n",
      "CATEGORIES same in small & validation:  [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"INGREDIENTS same in small & validation: \", ing_val == ing_small)\n",
    "print(\"CATEGORIES same in small & validation: \", cat_val == cat_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10687969-2e8e-4706-9c05-32271852a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In forbidden citrus vinaigrette\n",
      "In forbidden baton\n",
      "In forbidden capon\n",
      "In forbidden back ribs\n",
      "In forbidden amaranth\n",
      "In forbidden deli lunch\n",
      "In forbidden crema mexicana\n",
      "In forbidden gewurztraminer\n",
      "In forbidden epazote\n",
      "In forbidden pot roast\n",
      "In forbidden fresno chiles\n",
      "In forbidden demerara sugar\n",
      "In forbidden endive\n",
      "In forbidden indonesian sweet soy sauce\n",
      "In forbidden tallow\n",
      "In forbidden yellowfin tuna\n",
      "In forbidden style corn\n",
      "In forbidden freeze-dried strawberries\n",
      "In forbidden spring ragout\n",
      "In forbidden sauterne\n",
      "In forbidden frankfurters\n",
      "In forbidden pig\n",
      "In forbidden crusty rolls\n",
      "In forbidden fuyu persimmons\n",
      "In forbidden natural yogurt\n",
      "In forbidden xylitol sweetener\n",
      "In forbidden teriyaki\n",
      "In forbidden pasilla chiles\n"
     ]
    }
   ],
   "source": [
    "for i in ing_small:\n",
    "    if(i in small_forbidden_ing):\n",
    "        print(\"In forbidden\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f74ce33b-8651-4412-a7aa-e77a2d9c1198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF any ingr in validation are in forbidden?: True\n",
      "IF any ingr in train are in forbidden?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"IF any ingr in validation are in forbidden?:\", small_forbidden_ing.issubset(ing_val))\n",
    "print(\"IF any ingr in train are in forbidden?:\", small_forbidden_ing.issubset(ing_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "480b31e6-48d4-4873-805c-a4d6bfe72bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48847"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smaller_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc9e332a-9162-4bc6-97c3-dd725f198383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14700"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2a796ae-c0a6-4e1c-9dcb-5bf59fe21897",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df.to_csv('data/metadata/50k_FINAL_DATA.csv',  index = False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95ea3e77-09d4-4a69-8532-210cee44ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_df.to_csv('data/metadata/10k_FINAL_VAL_DATA.csv',  index = False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "700e308b-6c26-418f-b5d4-59dad3dfb471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID/File Name       0\n",
       "Category           0\n",
       "Calorie(kcal)      0\n",
       "Carbohydrate(g)    0\n",
       "Protein(g)         0\n",
       "Fat(g)             0\n",
       "Ingredients        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "smaller_df2 = pd.read_csv('data/metadata/50k_FINAL_TRAIN_DATA.csv', sep=\"\\t\")\n",
    "\n",
    "smaller_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f21af2-33c3-461c-966e-b217e4e7ef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID/File Name       0\n",
       "Category           0\n",
       "Calorie(kcal)      0\n",
       "Carbohydrate(g)    0\n",
       "Protein(g)         0\n",
       "Fat(g)             0\n",
       "Ingredients        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_val_df = pd.read_csv('data/metadata/15k_FINAL_VAL_DATA.csv', sep=\"\\t\")\n",
    "\n",
    "final_val_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ebb52-dd0f-41fa-8207-e5fa6998910a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
